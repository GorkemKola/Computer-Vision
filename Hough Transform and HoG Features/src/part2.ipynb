{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing libraries\n",
    "____________________\n",
    "numpy: array operations\n",
    "sklearn.svm: classifier\n",
    "cv2: image operations\n",
    "os: folder operations\n",
    "\n",
    "part1.hough_transform_circles: getting circles\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import cv2\n",
    "import os\n",
    "from part1 import hough_transform_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path, size=None, resized=False):\n",
    "    '''\n",
    "        To Read Images\n",
    "        _____________\n",
    "\n",
    "        Parameters\n",
    "        _____________\n",
    "        path : str\n",
    "            image path\n",
    "        size : int\n",
    "            to resize image\n",
    "        resized: bool\n",
    "            if true resize\n",
    "    '''\n",
    "    image = cv2.imread(path)\n",
    "    original_size = image.shape[0]\n",
    "    ratio = 1\n",
    "    if resized:\n",
    "        ratio = image.shape[1] / image.shape[0]\n",
    "        image = cv2.resize(image, (int(size * ratio), size))\n",
    "        ratio = original_size / image.shape[0]\n",
    "    return image, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating output directories\n",
    "os.makedirs('TestV_HoG', exist_ok=True)\n",
    "os.makedirs('TestR_HoG', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading paths and images and sizes and train labels\n",
    "test_r_paths = os.listdir('./TestR/')\n",
    "test_r_imgs, test_r_sizes = [], []\n",
    "for path in test_r_paths:\n",
    "    read_result = read_img(f'./TestR/{path}', 640, True)\n",
    "    test_r_imgs.append(read_result[0])\n",
    "    test_r_sizes.append(read_result[1])\n",
    "\n",
    "test_v_paths = os.listdir('./TestV/')\n",
    "test_v_imgs, test_v_sizes = [], []\n",
    "for path in test_v_paths:\n",
    "    read_result = read_img(f'./TestV/{path}', 640, True)\n",
    "    test_v_imgs.append(read_result[0])\n",
    "    test_v_sizes.append(read_result[1])\n",
    "\n",
    "train_paths = os.listdir('./Train/')\n",
    "train_imgs, train_sizes, train_labels = [], [], []\n",
    "for path in train_paths:\n",
    "    read_result = read_img(f'./Train/{path}', 128, True)\n",
    "    train_imgs.append(read_result[0])\n",
    "    train_sizes.append(read_result[1])\n",
    "\n",
    "    path = path.split('_')\n",
    "    path = path[0] + '_' + path[1]\n",
    "    train_labels.append(path)\n",
    "\n",
    "# to show the results\n",
    "test_v_original = []\n",
    "for path in test_v_paths:\n",
    "    read_result = read_img(f'./TestV/{path}')\n",
    "    test_v_original.append(read_result[0])\n",
    "\n",
    "test_r_original = []\n",
    "for path in test_r_paths:\n",
    "    read_result = read_img(f'./TestR/{path}')\n",
    "    test_r_original.append(read_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r_circles = [hough_transform_circles(img=img, \n",
    "                                          min_radius=8, \n",
    "                                          max_radius=65, \n",
    "                                          threshold=60,\n",
    "                                          show_inner=False) for img in test_r_imgs]\n",
    "\n",
    "test_v_circles = [hough_transform_circles(img=img, \n",
    "                                          min_radius=8, \n",
    "                                          max_radius=65, \n",
    "                                          threshold=60,\n",
    "                                          show_inner=False) for img in test_v_imgs]\n",
    "\n",
    "train_circles = [hough_transform_circles(img=img, \n",
    "                                          min_radius=4, \n",
    "                                          max_radius=65, \n",
    "                                          threshold=60,\n",
    "                                          show_inner=False) for img in train_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_images(image, circles, size):\n",
    "    '''\n",
    "        Crop Circles from image to apply train and prediction as square then makes outside the circle 0s\n",
    "\n",
    "        Parameters\n",
    "        ___________\n",
    "        image : np.array\n",
    "            Image will be cropped\n",
    "\n",
    "        circles : np.array\n",
    "            Contains Y, X coordinates and Radii of each circle\n",
    "\n",
    "        size : tuple(int, int)\n",
    "            Size of image\n",
    "\n",
    "        Returns\n",
    "        __________\n",
    "        found_images : np.array\n",
    "            found and cutted circles\n",
    "    '''\n",
    "    found_images = []\n",
    "    image = np.copy(image)\n",
    "    for y, x, r in circles:\n",
    "        y_start = max(0, y - r)\n",
    "        y_end = min(image.shape[0], y + r)\n",
    "        x_start = max(0, x - r)\n",
    "        x_end = min(image.shape[1], x + r)\n",
    "        \n",
    "        cropped = image[y_start:y_end, x_start:x_end]\n",
    "        # Create a mask for points outside the circle\n",
    "        y_indices, x_indices = np.ogrid[y_start:y_end, x_start:x_end]\n",
    "        mask = (y_indices - y)**2 + (x_indices - x)**2 - r**2 > 0\n",
    "\n",
    "        # Apply the mask to set values outside the circle to 0\n",
    "        cropped[mask] = 0\n",
    "        cropped = cv2.resize(cropped, size)\n",
    "        cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "        found_images.append(cropped)\n",
    "    return np.array(found_images)\n",
    "\n",
    "def save_to_hist(degrees, hist, magnitudes):\n",
    "    '''\n",
    "        This function save Orianted Gradient information to a histogram\n",
    "\n",
    "        Parameters\n",
    "        ___________\n",
    "        degrees : np.array\n",
    "            Oriantation of gradients\n",
    "\n",
    "        magnitudes : np.array\n",
    "            Magnitude of gradients\n",
    "\n",
    "        hist : np.array\n",
    "            Histogram of Orianted Gradients and Returns it\n",
    "    '''\n",
    "    hist_range = 180 / len(hist)\n",
    "    idxs = ((degrees / hist_range) - 1/2).astype(int)\n",
    "    hist[idxs%len(hist)] = np.minimum(magnitudes * (- degrees + (idxs+3/2) * hist_range) / hist_range, magnitudes)\n",
    "    hist[(idxs+1) % len(hist)] += np.maximum(magnitudes * (degrees - (idxs+1/2) * hist_range) / hist_range, 0)\n",
    "    return hist\n",
    "\n",
    "def get_angle_and_magnitudes(images):\n",
    "    '''\n",
    "        This funcion gives Oriantation and Magnitude information of image gradient\n",
    "\n",
    "        It first apply sobel filter to get gradients than calculates magnitude and oriantation\n",
    "        Parameters\n",
    "        __________\n",
    "        images : int\n",
    "            Image array\n",
    "\n",
    "        Returns\n",
    "        __________\n",
    "        gradient_magnitudes : np.array\n",
    "            magnitude of gradients \n",
    "\n",
    "        gradient_oriantations : np.array\n",
    "            oriantation of gradients\n",
    "    '''\n",
    "    sobel_x = cv2.Sobel(images, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(images, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitudes = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "    gradient_oriantations = np.arctan2(sobel_y, sobel_x + 1e-6)\n",
    "    return gradient_magnitudes, gradient_oriantations\n",
    "\n",
    "def get_hog(gradient_magnitudes, gradient_oriantation, patch_size):\n",
    "    '''\n",
    "        This function gives HoG features from magnitude and oriantation information with respect to a patch size information\n",
    "\n",
    "        Parameters\n",
    "        ___________\n",
    "        gradient_magnitudes : np.array\n",
    "            Magnitude of Gradients\n",
    "\n",
    "        gradient_oriantation : np.array\n",
    "            Oriantation of gradients\n",
    "\n",
    "        Returns\n",
    "        _________\n",
    "        hog: np.array\n",
    "            hog features of an image\n",
    "    '''\n",
    "    hog = []\n",
    "    for y in range(0, gradient_magnitudes.shape[0]-patch_size[0], patch_size[0]):\n",
    "        for x in range(0, gradient_magnitudes.shape[1]-patch_size[1], patch_size[1]):\n",
    "            grad = gradient_magnitudes[y:y+patch_size[0]*2, x:x+patch_size[1]*2].flatten()\n",
    "            angle = gradient_oriantation[y:y+patch_size[0]*2, x:x+patch_size[1]*2].flatten()\n",
    "\n",
    "            hist = np.zeros(4*9)\n",
    "            \n",
    "            for k in range(4):\n",
    "                hist[9*k:9*k+9] = save_to_hist(angle, hist[9*k:9*k+9], grad)\n",
    "            \n",
    "            hog.extend(hist)\n",
    "    return np.array(hog)\n",
    "\n",
    "def get_features(images, circles_arr, img_size, patch_size):\n",
    "    '''\n",
    "        This function give hog features of images\n",
    "\n",
    "        It crops coins from images first then calculate hog features of each coin and return it.\n",
    "        Parameters\n",
    "        __________\n",
    "        images : np.array\n",
    "            Image array\n",
    "\n",
    "        circles_arr : list[np.array]\n",
    "            Contains Y, X coordinates and Radii of each circle in each image\n",
    "\n",
    "        img_size : (int, int)\n",
    "            resizing cropped coins\n",
    "\n",
    "        patch_size : (int, int)\n",
    "            Size of each non-overlapping patch\n",
    "\n",
    "        Returns\n",
    "        _________\n",
    "        hogs : list[list[np.array]]\n",
    "            List contains hog information for all coins in each image.\n",
    "    '''\n",
    "    coins_arr = []\n",
    "    for i, image in enumerate(images):\n",
    "        circles = circles_arr[i]\n",
    "        coins = get_cropped_images(image, circles, img_size)\n",
    "        coins_arr.append(coins)\n",
    "    \n",
    "    hogs = []\n",
    "    for coins in coins_arr:\n",
    "        gradients, magnitudes = get_angle_and_magnitudes(coins)\n",
    "\n",
    "        hog = []\n",
    "        for gradient, magnitude in zip(gradients, magnitudes):\n",
    "            hog.append(get_hog(gradient, magnitude, patch_size))\n",
    "        hogs.append(hog)\n",
    "\n",
    "    return hogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting hog information\n",
    "test_v_hog = get_features(test_v_imgs, test_v_circles, (128, 128), (16, 16))\n",
    "test_r_hog = get_features(test_r_imgs, test_r_circles, (128, 128), (16, 16))\n",
    "train_hog = get_features(train_imgs, train_circles, (128, 128), (16, 16) )\n",
    "train_hog = np.array(train_hog)\n",
    "train_hog = train_hog.reshape(-1, train_hog.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training SVM Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_hog, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction code for test datasets\n",
    "def predict(features_arr, model):\n",
    "    preds = []\n",
    "    for features in features_arr:\n",
    "        pred = model.predict(features)\n",
    "        preds.append(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "test_v_pred = predict(test_v_hog, clf)\n",
    "test_r_pred = predict(test_r_hog, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_results(original_images, ratios, out_dir, preds_arr, circles_arr, paths):\n",
    "    '''\n",
    "        This function draws circles and writes predictions on image and then saves them.\n",
    "\n",
    "        Parameters\n",
    "        ____________\n",
    "        original_images : list[np.array]\n",
    "            List of images that are in original sizes\n",
    "\n",
    "        ratios : list[int]\n",
    "            ratio of original size / size of image\n",
    "\n",
    "        out_dir : str\n",
    "            Output directory\n",
    "\n",
    "        circles_arr : list[np.array]\n",
    "            contains each circle information in each image\n",
    "\n",
    "        paths : list[str]\n",
    "            output paths\n",
    "    '''\n",
    "    for circles, image, ratio, preds, path in zip(circles_arr, original_images, ratios, preds_arr, paths):\n",
    "        output = np.copy(image)\n",
    "        for circle, pred in zip(circles, preds):\n",
    "\n",
    "            circle = (ratio * circle).astype(int)\n",
    "            pos = circle[1]-50, circle[0] - circle[2]\n",
    "\n",
    "            cv2.circle(output, (circle[1], circle[0]), circle[2], (0, 0, 255), 4)\n",
    "            cv2.putText(output, pred, pos, cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 4)\n",
    "\n",
    "        output_path = f\"{out_dir}/{path}\"\n",
    "        cv2.imwrite(output_path, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results in TestV_HoG and TestR_HoG folders.\n",
    "draw_results(test_v_original, test_v_sizes, 'TestV_HoG', test_v_pred, test_v_circles, test_v_paths)\n",
    "draw_results(test_r_original, test_r_sizes, 'TestR_HoG', test_r_pred, test_r_circles, test_r_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
